{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks\n",
    "\n",
    "Here we will demonstrate some benchmarks against some alternatives.\n",
    "\n",
    "## Data\n",
    "\n",
    "UCI Credit card dataset with 30k rows and 23 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (30000, 24)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from skorecard.datasets import load_credit_card\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skorecard import Skorecard\n",
    "from skorecard.pipeline.bucketing_process import BucketingProcess\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skorecard.bucketers.bucketers import DecisionTreeBucketer, OptimalBucketer\n",
    "\n",
    "from time import time\n",
    "\n",
    "\n",
    "data = load_credit_card(as_frame=True)\n",
    "# data = pd.read_csv('UCI_Credit_Card.csv')\n",
    "# cols = [\"EDUCATION\", \"MARRIAGE\", \"LIMIT_BAL\", \"BILL_AMT1\", \"default\"]\n",
    "# data = data[cols]\n",
    "# data.rename(columns={'default': 'y'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"data shape: {data.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['y'], axis=1),\n",
    "    data[['y']], \n",
    "    test_size=0.25, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "data_train_opt, data_test_opt = train_test_split(\n",
    "    data,\n",
    "    test_size=0.25, \n",
    "    random_state=42\n",
    ")\n",
    "data_train_opt.head()\n",
    "\n",
    "\n",
    "y_train = y_train.to_numpy().flatten()\n",
    "y_test = y_test.to_numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def report_auc(clf, X_train, y_train, X_test, y_test):\n",
    "    proba_train = clf.predict_proba(X_train)[:,1]\n",
    "    proba_test = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    auc_train = round(roc_auc_score(y_train, proba_train),4) \n",
    "    auc_test = round(roc_auc_score(y_test, proba_test),4)\n",
    "\n",
    "    return auc_train, auc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memo import memlist, time_taken\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "\n",
    "@memlist(data=data)\n",
    "@time_taken()\n",
    "def fit_eval_record(clf, name, opt=False):\n",
    "    \n",
    "    if opt:\n",
    "        clf.fit(data_train_opt, data_train_opt['y'])\n",
    "        proba_train = clf.predict_proba(data_train_opt)[:,1]\n",
    "        proba_test = clf.predict_proba(data_test_opt)[:,1]\n",
    "\n",
    "        auc_train = round(roc_auc_score(y_train, proba_train),4) \n",
    "        auc_test = round(roc_auc_score(y_test, proba_test),4)\n",
    "        \n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        auc_train, auc_test = report_auc(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    return {'auc_train': auc_train, 'auc_test': auc_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skorecard is currently rather slow. A minor speed-up can be obtained by noting that both BucketingProcess and its pre-bucketers and bucketers compute identical bucket_tables and summaries: this is redundant when using a BucketingProcess. A boolean variable 'get_statistics' has been added to the bucketers to remove the calculation of these statistics. Below, a comparison is made to show the difference in speed this makes at the level of:\n",
    "### 1) A single bucketer\n",
    "### 2) A BucketingProcess\n",
    "### 3) A full Scorecard pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for a single bucket when summary is computed: 39.013752937316895\n",
      "Time for a single bucket when summary is not computed: 12.374780178070068\n"
     ]
    }
   ],
   "source": [
    "start_slow = time()\n",
    "for i in range(10):\n",
    "    bucketer_slow = DecisionTreeBucketer( max_n_bins=100, min_bin_size=0.05, get_statistics=True)\n",
    "    X_train_b1 = bucketer_slow.fit_transform(X_train, y_train)\n",
    "end_slow =  time()\n",
    "\n",
    "print('Time for a single bucket when summary is computed:', end_slow - start_slow)\n",
    "\n",
    "start = time()\n",
    "for i in range(10):\n",
    "    bucketer = DecisionTreeBucketer( max_n_bins=100, min_bin_size=0.05, get_statistics=False)\n",
    "    X_train_b2 = bucketer.fit_transform(X_train, y_train)\n",
    "end =  time()\n",
    "\n",
    "print('Time for a single bucket when summary is not computed:', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for a bucketing process when redundant summary is computed: 66.75277090072632\n",
      "Time for a bucketing process when redundant summary is not computed: 39.94823408126831\n"
     ]
    }
   ],
   "source": [
    "start_slow = time()\n",
    "for i in range(5):\n",
    "        clf_slow = BucketingProcess(\n",
    "        prebucketing_pipeline=make_pipeline(\n",
    "                        DecisionTreeBucketer( max_n_bins=100, min_bin_size=0.05, get_statistics=True)\n",
    "                ),\n",
    "                bucketing_pipeline=make_pipeline(\n",
    "                        OptimalBucketer( max_n_bins=10, min_bin_size=0.05, get_statistics=True)\n",
    "                )\n",
    "        )\n",
    "        clf_slow.fit(X_train, y_train)\n",
    "end_slow = time()\n",
    "print('Time for a bucketing process when redundant summary is computed:', end_slow - start_slow)\n",
    "\n",
    "start = time()\n",
    "for i in range(5):\n",
    "        clf = BucketingProcess(\n",
    "        prebucketing_pipeline=make_pipeline(\n",
    "                        DecisionTreeBucketer( max_n_bins=100, min_bin_size=0.05, get_statistics=False)\n",
    "                ),\n",
    "                bucketing_pipeline=make_pipeline(\n",
    "                        OptimalBucketer( max_n_bins=10, min_bin_size=0.05, get_statistics=False)\n",
    "                )\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "end = time()\n",
    "print('Time for a bucketing process when redundant summary is not computed:', end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/CK58LU/opt/anaconda3/envs/skorecard_env/lib/python3.9/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead.\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for a scorecard model when redundant summary is computed: 19.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/CK58LU/opt/anaconda3/envs/skorecard_env/lib/python3.9/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead.\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for a scorecard model when redundant summary is not computed: 13.61\n"
     ]
    }
   ],
   "source": [
    "bucketing_process_slow = BucketingProcess(\n",
    "    prebucketing_pipeline=make_pipeline(\n",
    "                DecisionTreeBucketer( max_n_bins=100, min_bin_size=0.05, get_statistics=True)\n",
    "        ),\n",
    "        bucketing_pipeline=make_pipeline(\n",
    "                OptimalBucketer( max_n_bins=10, min_bin_size=0.05, get_statistics=True)\n",
    "        )\n",
    ")\n",
    "scorecard_slow = Skorecard(bucketing=bucketing_process_slow)\n",
    "\n",
    "d_slow = fit_eval_record(scorecard_slow, name=\"skorecard.Scorecard\")\n",
    "print('Time for a scorecard model when redundant summary is computed:', d_slow['time_taken'])\n",
    "\n",
    "bucketing_process = BucketingProcess(\n",
    "    prebucketing_pipeline=make_pipeline(\n",
    "                DecisionTreeBucketer( max_n_bins=100, min_bin_size=0.05, get_statistics=False)\n",
    "        ),\n",
    "        bucketing_pipeline=make_pipeline(\n",
    "                OptimalBucketer( max_n_bins=10, min_bin_size=0.05, get_statistics=False)\n",
    "        )\n",
    ")\n",
    "\n",
    "scorecard = Skorecard(bucketing=bucketing_process)\n",
    "\n",
    "d = fit_eval_record(scorecard, name=\"skorecard.Scorecard\")\n",
    "print('Time for a scorecard model when redundant summary is not computed:', d['time_taken'])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97c4b6317b6033a8c2576103852a1a50de9911ff6385cd93d4a3534b7457ed3b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('skorecard_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
